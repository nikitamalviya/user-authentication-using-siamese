{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nikita/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nikita/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nikita/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nikita/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nikita/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nikita/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Shape : (18926, 211)\n",
      "\n",
      "After pre-processing : (11807, 29)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import preprocess\n",
    "import split_train_test\n",
    "import pair\n",
    "import features_and_labels\n",
    "import model\n",
    "importlib.reload(preprocess)\n",
    "importlib.reload(split_train_test)\n",
    "importlib.reload(pair)\n",
    "importlib.reload(features_and_labels)\n",
    "importlib.reload(model)\n",
    "\n",
    "from preprocess import (prepare_dataset,\n",
    "                        one_hot_encode, )\n",
    "\n",
    "from split_train_test import (id_split_train_test,\n",
    "                              print_dataset_details,\n",
    "                              get_train_test_split_data,\n",
    "                              print_train_test_value_counts,)\n",
    "\n",
    "from pair import (get_positive_pairs,\n",
    "                  validate_positive_pairs,\n",
    "                  get_negative_pairs,\n",
    "                  validate_negative_pairs,        \n",
    "                  balance_negative_pairs_equal_to_positive_pairs,\n",
    "                  validate_positive_and_negative_pairs,\n",
    "                  delete_redundant_columns,)\n",
    "\n",
    "from features_and_labels import(create_labels,\n",
    "                                reshape_X,\n",
    "                                reshape_y,\n",
    "                                split_train_validation,)\n",
    "\n",
    "from model import (create_model,)\n",
    "\n",
    "# dataset path \n",
    "\n",
    "dataset_path = 'dataset/tested_merged_data1.csv'\n",
    "keywords = ['mean','expected_result', 'user_id', 'sensors','inputs_dd_000','inputs_dd_001',\n",
    "            'inputs_dd_002', 'inputs_dd_003', 'inputs_dd_004']\n",
    "\n",
    "# get preprocessed dataset ( from preprocess.py )\n",
    "dataset = prepare_dataset(dataset_path, keywords) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT TRAIN TEST DATA\n",
    "\n",
    "    # from split_train_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Unique USER IDS in dataset :  196\n",
      "\n",
      "**** USERS SELECTION IS BASED ON EQUAL NUMBER OF GENUINE & FRAUD RECORDS ****\n",
      "\n",
      "Total Unique USER IDS having both fraud & genuine records :  123\n",
      "\n",
      "Users in TRAIN :  58\n",
      "\n",
      "Users in TEST: 13\n",
      "\n",
      "Users DROPPED: 52\n",
      "\n",
      "GENUINE & FRAUD RECORD COUNTS VIEW : \n",
      "\n",
      " [(253, 253), (182, 182), (170, 170), (152, 152), (142, 142), (134, 134), (114, 114), (96, 96), (89, 89), (84, 84), (77, 77), (74, 74), (71, 71), (70, 70), (68, 68), (65, 65), (65, 65), (62, 62), (59, 59), (58, 58), (56, 56), (53, 53), (52, 52), (51, 51), (46, 46), (46, 46), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (44, 44), (43, 43), (42, 42), (42, 42), (42, 42), (42, 42), (42, 42), (42, 42), (42, 42), (42, 42), (41, 41), (41, 41), (41, 41), (41, 41), (40, 40), (40, 40), (38, 38), (38, 38), (38, 38), (36, 36), (35, 35), (35, 35), (35, 35), (35, 35), (35, 35), (34, 34), (34, 34), (32, 32), (32, 32), (32, 32), (32, 32), (31, 31), (29, 29), (29, 29), (29, 29), (26, 26), (26, 26), (26, 26), (26, 26), (26, 26), (26, 26), (22, 22), (20, 20), (20, 20), (17, 17), (17, 17), (14, 14), (14, 14), (14, 14), (14, 14), (11, 11), (11, 11), (11, 11), (8, 8), (8, 8), (8, 8), (8, 8), (6, 6), (5, 5), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)]\n"
     ]
    }
   ],
   "source": [
    "max_range_of_records = 36\n",
    "min_range_of_records = 10\n",
    "\n",
    "# split IDs in train test \n",
    "common_user_ids, train_user_ids ,test_user_ids = id_split_train_test(dataset,\n",
    "                                                                             max_range_of_records,\n",
    "                                                                             min_range_of_records)\n",
    "# print status of data\n",
    "print_dataset_details(dataset, common_user_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET TRAIN TEST DATAFRAMES\n",
    "        # from split_train_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** DATASETS VALUE ****\n",
      "\n",
      "TRAIN DF :  (4176, 28)\n",
      "TEST DF :  (260, 28) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_train_records = max_range_of_records #(36)\n",
    "number_of_test_records = min_range_of_records  #(10)\n",
    "\n",
    "# get the splitted data\n",
    "train_df, test_df = get_train_test_split_data(dataset,\n",
    "                                             train_user_ids,\n",
    "                                             test_user_ids,\n",
    "                                             number_of_train_records,\n",
    "                                             number_of_test_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='red'>Unique users in training & testing </font>\n",
    "\n",
    "<font size=4 color='blue'> 36 records per user {genuine + fraud = 72} </font>\n",
    "\n",
    "<font size=4 color='blue'> 10 records per user {genuine + fraud = 20} </font>\n",
    "\n",
    "    # from split_train_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TRAIN :\n",
      "\n",
      " d2ebd2fb-0183-4d93-a7c8-6a162d1d    72\n",
      "19df8afe-3262-42b7-871c-f3d87e9d    72\n",
      "47551081-7af1-4c62-842f-b3f28b68    72\n",
      "4c499df0-ff3b-4231-bd07-7ff74dae    72\n",
      "4ff5b449-16b8-4ce8-9f1c-edb35b76    72\n",
      "27693542-8b55-4b16-a909-331b862e    72\n",
      "ea03edd8-0ca6-4302-a0a6-399ab3b9    72\n",
      "66cf099e-59fa-42be-890f-ed4fcd03    72\n",
      "8ad31046-f734-4008-b351-e1d744ed    72\n",
      "d4b18daa-0f06-4920-9dbe-8c25bcbe    72\n",
      "81279401-4a1c-4dd0-a6ba-dac4aeac    72\n",
      "578defd9-4912-4a5e-8549-35a6c891    72\n",
      "47c3ff02-141b-410c-a3a4-9cf03e51    72\n",
      "e8bcffff-8db4-4376-b3d0-f6063074    72\n",
      "4e631425-a08c-4352-817b-040320b3    72\n",
      "31d90bdf-7d73-4389-9532-c6174817    72\n",
      "a0848573-b8e7-46ba-9157-c89edaaf    72\n",
      "dd4fc622-42aa-467c-94c1-928dfcac    72\n",
      "86a7d333-beae-47a7-af1a-11fe981c    72\n",
      "9ae71631-31b2-4473-bdd6-31840bc7    72\n",
      "770b7817-ba15-45cc-8f2e-1ce49d3f    72\n",
      "b86146f6-5fc1-4b8b-bf72-ef3ede41    72\n",
      "f61f8475-1dec-4236-b132-d4660c34    72\n",
      "b63045cb-6fe0-4833-95df-8a15ee16    72\n",
      "218ee191-308e-4bae-a8f9-2d924d65    72\n",
      "3b94592f-8632-47b8-90c7-f5185a30    72\n",
      "d6a3eba6-7ee4-4c02-b33a-276d4212    72\n",
      "2c75a7c5-bffe-4fd3-9d3d-fb8be4c3    72\n",
      "18269bca-a8b3-4248-ba1c-fdc30ece    72\n",
      "1c9879e3-81f1-41b6-8123-90a777bf    72\n",
      "6c2d24fb-f440-461e-8ed1-e482d7c9    72\n",
      "4dc26621-951e-4aae-94f8-a362e96d    72\n",
      "9ffa3ee2-367c-4d0d-9fc8-4e1aa741    72\n",
      "98e3bd80-c2e5-42c8-923d-79a56131    72\n",
      "01b71d78-3850-45bf-8986-0c92fb51    72\n",
      "b50671e2-3a2a-49dd-b7e7-4fd349b4    72\n",
      "2229c5c9-ab7c-40ba-ae58-d018ab52    72\n",
      "bd78389d-436b-40cb-8cc5-2b9cd8fc    72\n",
      "674cf292-413f-41ee-9090-acc832fe    72\n",
      "2769ca04-408c-4fc0-80fe-44550ed4    72\n",
      "3b4eaa0f-692c-45fd-a85f-b1fd9a01    72\n",
      "981ddf8d-4b16-4690-99d1-256f5c6d    72\n",
      "bb7da591-b9c5-4e18-8441-e3e44b4d    72\n",
      "00f9c2c1-027e-452c-969f-ddb50962    72\n",
      "196cc75d-5acb-424a-9079-38032345    72\n",
      "657dc4a5-7802-4284-a69b-0dc27bc2    72\n",
      "bd7951b1-6670-491d-afc5-914ab10b    72\n",
      "7b26e08b-295d-4878-b117-518ee740    72\n",
      "5fbdc25f-3d6a-44a3-a612-ff2f2546    72\n",
      "c0604e2b-d4fa-4d1d-9db0-328556ae    72\n",
      "6ed156d0-2aec-43e1-856c-b292a44c    72\n",
      "31370cb1-a5f9-4c86-a75f-31a89b4c    72\n",
      "a28b85da-06ed-4eb6-b4da-d68ebac3    72\n",
      "19e47517-9897-44dc-b28b-8e6be166    72\n",
      "ed390fae-b7be-41ce-9130-399dd55a    72\n",
      "08c85030-0a3d-4a16-bfd8-9c29fe34    72\n",
      "fb477573-5578-4019-ac7b-e456a16a    72\n",
      "7c6e0788-f155-4cec-8a8e-7496e5e7    72\n",
      "Name: user_id, dtype: int64\n",
      "\n",
      "\n",
      "TEST :\n",
      "\n",
      " 8e6b5654-4e3f-4df0-9bfa-ab38c297    20\n",
      "da6c57e6-0395-4a43-8e8f-287c0176    20\n",
      "dafec9b9-7bf6-41dc-b233-0c176027    20\n",
      "878dc095-984e-4959-ae81-7c9abd9a    20\n",
      "02dafb6c-0063-4616-8f9b-3856cf87    20\n",
      "a0a5ec3d-942f-446c-9fd9-0cf9131d    20\n",
      "f61c7373-7c1c-4bca-b503-6c6a3f0a    20\n",
      "1357b004-f888-41f3-8eb0-2c687521    20\n",
      "7c0ac481-70e8-4f32-99c5-1334746c    20\n",
      "8eb271d5-ab09-4e0e-b889-b56d1be1    20\n",
      "cfbc4f11-442a-44a4-bd20-701d3dda    20\n",
      "8d053385-4625-4924-bbae-c7f7b6d1    20\n",
      "595e2e22-32b3-4aa8-9512-84d55272    20\n",
      "Name: user_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_train_test_value_counts(train_df, test_df, train_user_ids ,test_user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT ENCODE TRAIN & TEST DATAFRAMES - (user_id)\n",
    "    # from preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = one_hot_encode(train_df, 'user_id')\n",
    "test_df = one_hot_encode(test_df, 'user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPARATE POSITIVE & NEGATIVE DATA  IN TRAIN & TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN POSITIVE RECORDS : (2088, 28)\n",
      "TRAIN NEGATIVE RECORDS : (2088, 28)\n",
      "\n",
      "TEST POSITIVE RECORDS : (130, 28)\n",
      "TEST NEGATIVE RECORDS : (130, 28)\n"
     ]
    }
   ],
   "source": [
    "train_positives_df = train_df.query('(expected_result == 1)')\n",
    "train_negatives_df = train_df.query('(expected_result == -1)')\n",
    "\n",
    "test_positives_df = test_df.query('(expected_result == 1)')\n",
    "test_negatives_df = test_df.query('(expected_result == -1)')\n",
    "\n",
    "print(f\"\\nTRAIN POSITIVE RECORDS : {train_positives_df.shape}\")\n",
    "print(f\"TRAIN NEGATIVE RECORDS : {train_negatives_df.shape}\")\n",
    "print(f\"\\nTEST POSITIVE RECORDS : {test_positives_df.shape}\")\n",
    "print(f\"TEST NEGATIVE RECORDS : {test_negatives_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_result</th>\n",
       "      <th>inputs_dd_000</th>\n",
       "      <th>inputs_dd_001</th>\n",
       "      <th>inputs_dd_002</th>\n",
       "      <th>inputs_dd_003</th>\n",
       "      <th>inputs_dd_004</th>\n",
       "      <th>motion_A_0_mean</th>\n",
       "      <th>motion_A_1_mean</th>\n",
       "      <th>motion_A_2_mean</th>\n",
       "      <th>motion_G_0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>motion_R_0_mean</th>\n",
       "      <th>motion_R_1_mean</th>\n",
       "      <th>motion_R_2_mean</th>\n",
       "      <th>motion_Y_0_mean</th>\n",
       "      <th>motion_Y_1_mean</th>\n",
       "      <th>motion_Y_2_mean</th>\n",
       "      <th>motion_a_0_mean</th>\n",
       "      <th>motion_a_1_mean</th>\n",
       "      <th>motion_a_2_mean</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>1</td>\n",
       "      <td>0.143996</td>\n",
       "      <td>0.197712</td>\n",
       "      <td>0.175011</td>\n",
       "      <td>0.270820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093804</td>\n",
       "      <td>5.617165</td>\n",
       "      <td>8.314385</td>\n",
       "      <td>0.029451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220718</td>\n",
       "      <td>0.196895</td>\n",
       "      <td>0.638908</td>\n",
       "      <td>-0.007516</td>\n",
       "      <td>-0.029335</td>\n",
       "      <td>-0.004320</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>0.075397</td>\n",
       "      <td>0.207277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220325</td>\n",
       "      <td>0.132894</td>\n",
       "      <td>0.252969</td>\n",
       "      <td>0.256306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.089522</td>\n",
       "      <td>7.012722</td>\n",
       "      <td>7.003768</td>\n",
       "      <td>-0.100165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302824</td>\n",
       "      <td>0.232009</td>\n",
       "      <td>0.550533</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>-0.008654</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>0.096375</td>\n",
       "      <td>0.116030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      expected_result  inputs_dd_000  inputs_dd_001  inputs_dd_002  \\\n",
       "2143                1       0.143996       0.197712       0.175011   \n",
       "2188                1       0.220325       0.132894       0.252969   \n",
       "\n",
       "      inputs_dd_003  inputs_dd_004  motion_A_0_mean  motion_A_1_mean  \\\n",
       "2143       0.270820            0.0         0.093804         5.617165   \n",
       "2188       0.256306            0.0        -0.089522         7.012722   \n",
       "\n",
       "      motion_A_2_mean  motion_G_0_mean  ...  motion_R_0_mean  motion_R_1_mean  \\\n",
       "2143         8.314385         0.029451  ...         0.220718         0.196895   \n",
       "2188         7.003768        -0.100165  ...         0.302824         0.232009   \n",
       "\n",
       "      motion_R_2_mean  motion_Y_0_mean  motion_Y_1_mean  motion_Y_2_mean  \\\n",
       "2143         0.638908        -0.007516        -0.029335        -0.004320   \n",
       "2188         0.550533         0.002607        -0.008654        -0.000132   \n",
       "\n",
       "      motion_a_0_mean  motion_a_1_mean  motion_a_2_mean  user_id  \n",
       "2143         0.070737         0.075397         0.207277        0  \n",
       "2188         0.010643         0.096375         0.116030        0  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_positives_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_result</th>\n",
       "      <th>inputs_dd_000</th>\n",
       "      <th>inputs_dd_001</th>\n",
       "      <th>inputs_dd_002</th>\n",
       "      <th>inputs_dd_003</th>\n",
       "      <th>inputs_dd_004</th>\n",
       "      <th>motion_A_0_mean</th>\n",
       "      <th>motion_A_1_mean</th>\n",
       "      <th>motion_A_2_mean</th>\n",
       "      <th>motion_G_0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>motion_R_0_mean</th>\n",
       "      <th>motion_R_1_mean</th>\n",
       "      <th>motion_R_2_mean</th>\n",
       "      <th>motion_Y_0_mean</th>\n",
       "      <th>motion_Y_1_mean</th>\n",
       "      <th>motion_Y_2_mean</th>\n",
       "      <th>motion_a_0_mean</th>\n",
       "      <th>motion_a_1_mean</th>\n",
       "      <th>motion_a_2_mean</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.245908</td>\n",
       "      <td>0.375753</td>\n",
       "      <td>0.706719</td>\n",
       "      <td>0.18553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>6.484320</td>\n",
       "      <td>7.589210</td>\n",
       "      <td>0.634965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242845</td>\n",
       "      <td>0.252376</td>\n",
       "      <td>0.733069</td>\n",
       "      <td>-0.025758</td>\n",
       "      <td>-0.007999</td>\n",
       "      <td>-0.022977</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.113257</td>\n",
       "      <td>0.187677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.167540</td>\n",
       "      <td>0.124143</td>\n",
       "      <td>0.331750</td>\n",
       "      <td>0.19819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776021</td>\n",
       "      <td>6.126912</td>\n",
       "      <td>7.927501</td>\n",
       "      <td>0.803202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307191</td>\n",
       "      <td>0.090773</td>\n",
       "      <td>0.375153</td>\n",
       "      <td>-0.059509</td>\n",
       "      <td>-0.171004</td>\n",
       "      <td>-0.320601</td>\n",
       "      <td>-0.101103</td>\n",
       "      <td>0.082505</td>\n",
       "      <td>0.281851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      expected_result  inputs_dd_000  inputs_dd_001  inputs_dd_002  \\\n",
       "2101               -1       0.245908       0.375753       0.706719   \n",
       "2100               -1       0.167540       0.124143       0.331750   \n",
       "\n",
       "      inputs_dd_003  inputs_dd_004  motion_A_0_mean  motion_A_1_mean  \\\n",
       "2101        0.18553            0.0         0.617978         6.484320   \n",
       "2100        0.19819            0.0         0.776021         6.126912   \n",
       "\n",
       "      motion_A_2_mean  motion_G_0_mean  ...  motion_R_0_mean  motion_R_1_mean  \\\n",
       "2101         7.589210         0.634965  ...         0.242845         0.252376   \n",
       "2100         7.927501         0.803202  ...         0.307191         0.090773   \n",
       "\n",
       "      motion_R_2_mean  motion_Y_0_mean  motion_Y_1_mean  motion_Y_2_mean  \\\n",
       "2101         0.733069        -0.025758        -0.007999        -0.022977   \n",
       "2100         0.375153        -0.059509        -0.171004        -0.320601   \n",
       "\n",
       "      motion_a_0_mean  motion_a_1_mean  motion_a_2_mean  user_id  \n",
       "2101         0.002904         0.113257         0.187677        0  \n",
       "2100        -0.101103         0.082505         0.281851        0  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_negatives_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET POSITIVE & NEGATIVE  PAIRS : <font color='blue'> TRAINING </font>\n",
    "    # from pair.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/Nikita/Projects/GIT/user-authentication-using-siamese/pair.py:22: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  user_data = user_data_df.as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN POSITIVE PAIRS : (36540, 56) using (2088, 28) train positive records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/Nikita/Projects/GIT/user-authentication-using-siamese/pair.py:57: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  user_positive_data = positive_user_data_df.as_matrix()\n",
      "/home/nikita/Nikita/Projects/GIT/user-authentication-using-siamese/pair.py:58: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  user_negative_data = negative_user_data_df.as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN NEGATIVE PAIRS : (75168, 56) using (2088, 28) train negative records.\n"
     ]
    }
   ],
   "source": [
    "''' POSITIVE PAIRS '''\n",
    "\n",
    "train_positive_pairs = get_positive_pairs(train_positives_df, train_positives_df['user_id'].unique())\n",
    "print(f\"\\nTRAIN POSITIVE PAIRS : {train_positive_pairs.shape} using {train_positives_df.shape} train positive records.\")\n",
    "\n",
    "# print(type(train_negatives_df), type(train_positives_df))\n",
    "\n",
    "''' NEGATIVE PAIRS '''\n",
    "# make positive pairs \n",
    "train_negative_pairs = get_negative_pairs(train_negatives_df, train_positives_df, train_negatives_df['user_id'].unique())\n",
    "print(f\"TRAIN NEGATIVE PAIRS : {train_negative_pairs.shape} using {train_negatives_df.shape} train negative records.\")\n",
    "\n",
    "# ''' GET EQUAL POSITIVE & NEGATIVE PAIRS \n",
    "# # balancing positive & negative pairs\n",
    "# balanced_negative_pairs = balance_negative_pairs_equal_to_positive_pairs(train_negative_pairs)\n",
    "# # validate balanced pairs\n",
    "# validate_positive_and_negative_pairs(len(train_positive_pairs), len(balanced_negative_pairs)) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of POSITIVE PAIR ROW :\n",
      "[ 1.00000000e+00  1.68116000e-01  2.28227300e-01  2.48105100e-01\n",
      "  3.12209600e-01  0.00000000e+00 -4.40755720e-01  5.11401500e+00\n",
      "  8.56745600e+00 -2.87455440e-01  5.08279280e+00  8.32782900e+00\n",
      "  3.62908630e+01  1.90586650e+00 -5.17275670e+00 -1.42763960e+00\n",
      " -5.46674200e-01  5.00124300e-02  1.92246650e-01  1.89653340e-01\n",
      "  6.35622260e-01 -1.95395440e-02  1.27240690e-01  9.31144950e-02\n",
      " -1.24985576e-01  8.31490600e-02  2.45967400e-01  0.00000000e+00\n",
      "  1.00000000e+00  1.91728600e-01  1.96550600e-01  1.96769300e-01\n",
      "  2.58984500e-01  0.00000000e+00 -6.47445900e-02  5.59892600e+00\n",
      "  8.03305300e+00  8.03189050e-02  5.46342230e+00  8.07887500e+00\n",
      " -1.95008530e+00  7.30764900e+00 -2.79142670e+01  9.26725100e-02\n",
      " -6.08467600e-01  6.67863340e-03  2.70560530e-01 -3.24646690e-03\n",
      " -4.19465100e-02  8.05368500e-02  2.30216100e-01  3.46195640e-01\n",
      " -1.19300574e-01  1.20531045e-01 -3.63791300e-02  0.00000000e+00]\n",
      "\n",
      "Sample of NEGATIVE PAIR ROW :\n",
      "[ 1.00000000e+00  1.68116000e-01  2.28227300e-01  2.48105100e-01\n",
      "  3.12209600e-01  0.00000000e+00 -4.40755720e-01  5.11401500e+00\n",
      "  8.56745600e+00 -2.87455440e-01  5.08279280e+00  8.32782900e+00\n",
      "  3.62908630e+01  1.90586650e+00 -5.17275670e+00 -1.42763960e+00\n",
      " -5.46674200e-01  5.00124300e-02  1.92246650e-01  1.89653340e-01\n",
      "  6.35622260e-01 -1.95395440e-02  1.27240690e-01  9.31144950e-02\n",
      " -1.24985576e-01  8.31490600e-02  2.45967400e-01  0.00000000e+00\n",
      " -1.00000000e+00  1.85278800e-01  1.02677200e-01  3.85777900e-01\n",
      "  2.18558100e-01  0.00000000e+00  6.27359200e-01  5.94075900e+00\n",
      "  8.24265000e+00  7.12667700e-01  5.91958950e+00  7.74953940e+00\n",
      " -3.92393520e+00 -2.21205920e+01  1.09676070e+01  3.93423320e-01\n",
      " -6.21790200e-01 -7.68155800e-02  6.54196500e-02 -3.51704620e-02\n",
      " -8.38262960e-02  2.69942340e-02  1.45753480e-02 -5.66268940e-02\n",
      " -8.09130100e-02  7.18810600e-02  4.45539390e-01  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample of POSITIVE PAIR ROW :\\n{train_positive_pairs[0]}\")\n",
    "print(f\"\\nSample of NEGATIVE PAIR ROW :\\n{train_negative_pairs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE REDUNDANCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36540, 53) (75168, 53)\n",
      "(36540, 53) (75168, 53)\n"
     ]
    }
   ],
   "source": [
    "''' Remove existing labels from the dataframes to reduce redundancy in the pair data '''\n",
    "\n",
    "train_positive_pairs = delete_redundant_columns(train_positive_pairs, 0)\n",
    "train_negative_pairs = delete_redundant_columns(train_negative_pairs, 0)\n",
    "train_positive_pairs = delete_redundant_columns(train_positive_pairs, 27)\n",
    "train_negative_pairs = delete_redundant_columns(train_negative_pairs, 27)\n",
    "train_positive_pairs = delete_redundant_columns(train_positive_pairs, -1)\n",
    "train_negative_pairs = delete_redundant_columns(train_negative_pairs, -1)\n",
    "\n",
    "print(train_positive_pairs.shape, train_negative_pairs.shape)\n",
    "print(train_positive_pairs.shape, train_negative_pairs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE LABELS\n",
    "\n",
    "    # from features_and_labels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels : [1.]\n",
      "Length of labels : 36540\n",
      "Training data shape : (36540, 54)\n",
      "Sample training row :\n",
      "[ 1.68116000e-01  2.28227300e-01  2.48105100e-01  3.12209600e-01\n",
      "  0.00000000e+00 -4.40755720e-01  5.11401500e+00  8.56745600e+00\n",
      " -2.87455440e-01  5.08279280e+00  8.32782900e+00  3.62908630e+01\n",
      "  1.90586650e+00 -5.17275670e+00 -1.42763960e+00 -5.46674200e-01\n",
      "  5.00124300e-02  1.92246650e-01  1.89653340e-01  6.35622260e-01\n",
      " -1.95395440e-02  1.27240690e-01  9.31144950e-02 -1.24985576e-01\n",
      "  8.31490600e-02  2.45967400e-01  0.00000000e+00  1.91728600e-01\n",
      "  1.96550600e-01  1.96769300e-01  2.58984500e-01  0.00000000e+00\n",
      " -6.47445900e-02  5.59892600e+00  8.03305300e+00  8.03189050e-02\n",
      "  5.46342230e+00  8.07887500e+00 -1.95008530e+00  7.30764900e+00\n",
      " -2.79142670e+01  9.26725100e-02 -6.08467600e-01  6.67863340e-03\n",
      "  2.70560530e-01 -3.24646690e-03 -4.19465100e-02  8.05368500e-02\n",
      "  2.30216100e-01  3.46195640e-01 -1.19300574e-01  1.20531045e-01\n",
      " -3.63791300e-02  1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "''' Create labels for training data '''\n",
    "\n",
    "pos_neg_flag = False\n",
    "\n",
    "if pos_neg_flag:\n",
    "    labels = create_labels(train_positive_pairs, train_negative_pairs[:len(train_positive_pairs)], pos_neg_flag)\n",
    "    train_data = np.hstack([np.vstack([train_positive_pairs, train_negative_pairs[:len(train_positive_pairs)]]), labels])\n",
    "else:\n",
    "    labels = create_labels(train_positive_pairs)\n",
    "    train_data = np.hstack([np.vstack([train_positive_pairs]), labels])\n",
    "\n",
    "print(f\"Unique labels : {np.unique(labels)}\\nLength of labels : {len(labels)}\\nTraining data shape : {train_data.shape}\\nSample training row :\\n{train_data[0]}\")\n",
    "\n",
    "\n",
    "''' Shuffle training data '''\n",
    "np.random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES & LABELS\n",
    "    # from features_and_labels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(features_and_labels)\n",
    "from features_and_labels import(create_labels,\n",
    "                                reshape_X,\n",
    "                                reshape_y,\n",
    "                                split_train_validation,)\n",
    "\n",
    "nrows = (train_data.shape[0])\n",
    "ncols = (train_data.shape[1])\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, (36540, 54), (36540, 54), 26)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape[0]-1, train_data.shape, train_data.shape, (train_data[0].shape[0]-1)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Split labels & fetaures '''\n",
    "X, y = train_data_t, train_data[:, -1]\n",
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Reshape y '''\n",
    "y_ = reshape_y(y, nrows)\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Split X & y'''\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_train_validation(X, y_, VALIDATION_SPLIT)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0], y_train[0], x_train,y_train, x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL\n",
    "    # from model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7cefb53f428d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mreshape_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0ma0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "import model\n",
    "importlib.reload(model)\n",
    "from keras.optimizers import Adam\n",
    "from model import (create_model,)\n",
    "\n",
    "''' Model initialzations '''\n",
    "\n",
    "INPUT_SHAPE = [None, 2]\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "# input shape (X)\n",
    "Tx, n_in = nrows, ncols\n",
    "\n",
    "# number of columns in 2 input rows\n",
    "n_a = 27\n",
    "\n",
    "# number of outputs \n",
    "n_out =  1\n",
    "\n",
    "reshape_row, reshape_col = 1, 4\n",
    "\n",
    "a0 = np.zeros((x_train.shape[0], n_a))\n",
    "\n",
    "c0 = np.zeros((x_train.shape[0], n_a))\n",
    "\n",
    "optimizer = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-262c30f13902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/0_PRAEMINEO/GIT/neoeyed/behaviour-based-authentication-siamese-rnn-model2/model.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(Tx, n_in, n_a, n_out, reshape_row, reshape_col)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshapor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m             if all([s is not None\n\u001b[1;32m    473\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# input shape known? then we can compute the output shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             return (input_shape[0],) + self._fix_unknown_dimension(\n\u001b[0;32m--> 398\u001b[0;31m                 input_shape[1:], self.target_shape)\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "model = create_model(Tx, n_in, n_a, n_out, reshape_row, reshape_col)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_train, a0, c0], list(y_train), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0_t = np.zeros((x_test.shape[0], n_a))\n",
    "c0_t = np.zeros((x_test.shape[0], n_a))\n",
    "\n",
    "x_test[0], y_test[0], x_test[0].shape, y_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate([x_test, a0_t, c0_t], list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACCURACY :\\n\", evaluation[16:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train_positive_pairs \n",
    "# y = labels\n",
    "# val_split = 10\n",
    "\n",
    "# # X = train_positive_pairs[:,1:] \n",
    "# # y = train_positive_pairs[:,0]\n",
    "# # val_size = 1000\n",
    "\n",
    "# # split_train_validation(X, y, val_split)\n",
    "\n",
    "# # X[:2], y, np.unique(y)\n",
    "\n",
    "# split_train_validation(X, y, val_split)\n",
    "\n",
    "# X[:2], y, np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[:val_size], y[:, :val_size, :], X[val_size:], y[:,val_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = np.hstack([np.vstack([train_positive_pairs]), labels])\n",
    "# all_data_t = np.zeros((all_data.shape[0], 15, 4))\n",
    "\n",
    "\n",
    "# ctr = 0\n",
    "# for i, j in zip(range(0, 30, 2), range(30, 60, 2)):\n",
    "#     all_data_t[:, ctr, :] = np.hstack([all_data[:, i:i+2], all_data[:, j:j+2]])\n",
    "#     ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
